{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from utils import parse_m_file, compute_PTDF\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True, floatmode='fixed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "num_scenarios = 2\n",
    "perturbation_scale = 0.9\n",
    "baseMVA = 100\n",
    "\n",
    "# Load data\n",
    "bus_data, gen_data, branch_data, gencost_data = parse_m_file('pglib_opf_case14_ieee.m')\n",
    "num_buses = bus_data.shape[0]\n",
    "num_generators = gen_data.shape[0]\n",
    "num_lines = branch_data.shape[0]\n",
    "num_branches = branch_data.shape[0]\n",
    "\n",
    "# Data Extraction\n",
    "Pd_base = bus_data[:, 2]\n",
    "Pg_min = gen_data[:, 9]\n",
    "Pg_max = gen_data[:, 8]\n",
    "Pg_max[0] = 400\n",
    "Pg_max[1] = 100\n",
    "cost_coeff_true = gencost_data[:, 5]\n",
    "\n",
    "branch_data_congested = branch_data.copy()\n",
    "branch_data_congested[:, 5] *= 0.7  # reduce limits by 30%\n",
    "\n",
    "# PTDF = compute_PTDF(branch_data, bus_data)\n",
    "PTDF = compute_PTDF(branch_data_congested, bus_data)\n",
    "\n",
    "\n",
    "# Generator incidence matrix\n",
    "gen_to_bus = np.zeros((num_buses, num_generators))\n",
    "for i, gen_bus in enumerate(gen_data[:, 0].astype(int) - 1):\n",
    "    gen_to_bus[gen_bus, i] = 1\n",
    "\n",
    "# Storage for scenario data\n",
    "Pg_scenarios = []\n",
    "lambda_slack_scenarios = []\n",
    "nu_max_scenarios = []\n",
    "nu_min_scenarios = []\n",
    "mu_min_scenarios = []\n",
    "mu_max_scenarios = []\n",
    "Pd_scenarios = []\n",
    "\n",
    "scenario_count = 0\n",
    "np.random.seed(42)\n",
    "\n",
    "while scenario_count < num_scenarios:\n",
    "    Pd_perturbed = Pd_base * (1 + np.random.uniform(-perturbation_scale, perturbation_scale, size=num_buses))\n",
    "    #Pd_perturbed = np.random.randint(0, 100, size=Pd_base.shape) + np.random.randint(0, 100, size=Pd_base.shape)/100\n",
    "    Pd_perturbed[0] = 0  # slack bus\n",
    "    Pd_scenarios.append(Pd_perturbed)\n",
    "    \n",
    "    Pg = cp.Variable(num_generators)\n",
    "    P_inj = gen_to_bus @ Pg - Pd_perturbed\n",
    "    P_inj_reduced = P_inj[1:]\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(Pg) == np.sum(Pd_perturbed),\n",
    "        Pg >= Pg_min,\n",
    "        Pg <= Pg_max,\n",
    "        -branch_data_congested[:, 5] <= PTDF @ P_inj_reduced,\n",
    "        PTDF @ P_inj_reduced <= branch_data_congested[:, 5]\n",
    "    ]\n",
    "\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(cost_coeff_true, Pg)))\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.MOSEK, verbose=False)\n",
    "\n",
    "    if prob.status == 'optimal':\n",
    "        scenario_count += 1\n",
    "        Pg_scenarios.append(Pg.value)\n",
    "        Pd_scenarios.append(Pd_perturbed)\n",
    "        lambda_slack_scenarios.append(constraints[0].dual_value)\n",
    "        nu_min_scenarios.append(constraints[3].dual_value)\n",
    "        nu_max_scenarios.append(constraints[4].dual_value)\n",
    "        mu_min_scenarios.append(constraints[1].dual_value)\n",
    "        mu_max_scenarios.append(constraints[2].dual_value)\n",
    "        print(f\"Scenario {scenario_count}/{num_scenarios} generated.\")\n",
    "\n",
    "Pg_scenarios = np.array(Pg_scenarios)\n",
    "lambda_slack_scenarios = np.array(lambda_slack_scenarios)\n",
    "nu_max_scenarios = np.array(nu_max_scenarios)\n",
    "nu_min_scenarios = np.array(nu_min_scenarios)\n",
    "mu_min_scenarios = np.array(mu_min_scenarios)\n",
    "mu_max_scenarios = np.array(mu_max_scenarios)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lambda_slack_scenarios:\\n\", lambda_slack_scenarios)\n",
    "print(\"Pg_scenarios:\\n\", Pg_scenarios)\n",
    "print(\"Pd_scenarios:\\n\", Pd_scenarios)\n",
    "print(\"nu_max_scenarios:\\n\", nu_max_scenarios)\n",
    "print(\"nu_min_scenarios:\\n\", nu_min_scenarios)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a354223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Optimization (using multiple scenarios)\n",
    "c = cp.Variable(num_generators, nonneg=True)\n",
    "loss = 0\n",
    "\n",
    "Pg_inv = cp.Variable((num_scenarios, num_generators))\n",
    "lambda_slack_inv = cp.Variable(num_scenarios)   \n",
    "nu_min_inv = cp.Variable((num_scenarios, num_lines))\n",
    "nu_max_inv = cp.Variable((num_scenarios, num_lines))\n",
    "mu_min_inv = cp.Variable((num_scenarios, num_generators))\n",
    "mu_max_inv = cp.Variable((num_scenarios, num_generators))\n",
    "\n",
    "constraints_inv = []\n",
    "stationarity = []\n",
    "primal_feasibility = []\n",
    "dual_feasibility = []\n",
    "complementary = []\n",
    "\n",
    "for t in range(num_scenarios):\n",
    "    \n",
    "    P_inj_inv = gen_to_bus @ Pg_inv[t] - Pd_scenarios[t]\n",
    "    P_inj_reduced_inv = P_inj_inv[1:]\n",
    "    flow_lines = PTDF @ P_inj_reduced_inv\n",
    "    \n",
    "    for gen in range(num_generators):\n",
    "        # stationarity condition for generator\n",
    "        stationarity.append(\n",
    "            c[gen] + lambda_slack_inv[t] + mu_max_inv[t][gen] - mu_max_inv[t][gen]      \n",
    "                    + (nu_max_inv[t] - nu_min_inv[t]) @ PTDF @ gen_to_bus[1:, gen] == 0\n",
    "        )\n",
    "    \n",
    "    primal_feasibility += [\n",
    "        cp.sum(Pg_inv) == np.sum(Pd_scenarios[t]),\n",
    "        Pg_inv >= Pg_min,\n",
    "        Pg_inv <= Pg_max,\n",
    "        -branch_data[:, 5] <= flow_lines,\n",
    "        flow_lines <= branch_data[:, 5]\n",
    "    ]\n",
    "\n",
    "    dual_feasibility += [\n",
    "        mu_min_inv >= 0,\n",
    "        mu_max_inv >= 0,\n",
    "        nu_min_inv >= 0,\n",
    "        nu_max_inv >= 0\n",
    "    ]\n",
    "    \n",
    "    # Complementary slackness conditions\n",
    "    for i in range(num_branches):\n",
    "        # nu_min * (- branch_data_congested[:, 5] - PTDF @ P_inj_reduced) == 0\n",
    "        if nu_min_scenarios[t][i] != 0:\n",
    "            complementary.append(-branch_data_congested[i, 5] == flow_lines[i])\n",
    "            dual_feasibility.append(nu_max_inv[t][i] == 0)\n",
    "        # nu_max * (PTDF @ P_inj_reduced - branch_data_congested[:, 5]) == 0 \n",
    "        elif nu_max_scenarios[t][i] != 0:\n",
    "            complementary.append(flow_lines[i] == branch_data_congested[i, 5])\n",
    "            dual_feasibility.append(nu_min_inv[t][i] == 0) # check this\n",
    "        else:     \n",
    "            complementary.append(nu_min_inv[t][i] == 0)\n",
    "            complementary.append(nu_max_inv[t][i] == 0)\n",
    "\n",
    "    \n",
    "    for i in range(num_generators):\n",
    "        # mu_max * (Pg - Pg_max) == 0\n",
    "        if Pg_scenarios[t][i] == Pg_max[i]:\n",
    "            dual_feasibility.append(mu_max_inv[t][i] >= 0)\n",
    "            dual_feasibility.append(mu_min_inv[t][i] == 0)\n",
    "        # mu_min * (Pg_min - Pg) == 0\n",
    "        elif Pg_scenarios[t][i] == Pg_min[i]:\n",
    "            dual_feasibility.append(mu_min_inv[t][i] >= 0)\n",
    "            dual_feasibility.append(mu_max_inv[t][i] == 0)\n",
    "        else:\n",
    "            dual_feasibility.append(mu_max_inv[t][i] == 0)\n",
    "            dual_feasibility.append(mu_min_inv[t][i] == 0)\n",
    "    \n",
    "    \n",
    "constraints_inv += stationarity + primal_feasibility  + dual_feasibility + complementary\n",
    "\n",
    "constraints_inv.append(c[2:5] == 0)\n",
    "\n",
    "loss += cp.sum_squares(Pg_inv - Pg_scenarios)\n",
    "loss += cp.sum_squares(lambda_slack_inv - lambda_slack_scenarios)\n",
    "loss += cp.sum_squares(mu_min_inv - mu_min_scenarios)\n",
    "loss += cp.sum_squares(mu_max_inv - mu_max_scenarios)\n",
    "loss += cp.sum_squares(nu_min_inv - nu_min_scenarios)\n",
    "loss += cp.sum_squares(nu_max_inv - nu_max_scenarios)\n",
    "\n",
    "\n",
    "loss *= 1 / num_scenarios\n",
    "\n",
    "inv_prob = cp.Problem(cp.Minimize(loss), constraints_inv)\n",
    "inv_prob.solve(solver=cp.MOSEK, verbose=True)\n",
    "\n",
    "if inv_prob.status == 'optimal':\n",
    "    print(\"Inferred cost coefficients: \", c.value)\n",
    "    print(\"Optimal cost: \", inv_prob.value)\n",
    "else:\n",
    "    print(\"Inverse problem not optimal: \", inv_prob.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1854c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inferred cost coefficients: \", c.value)\n",
    "print(\"True cost coefficients: \", cost_coeff_true)\n",
    "\n",
    "# Inverse Optimization Variables\n",
    "print(\"loss:\\n\", loss.value)\n",
    "print(\"Pg_inv:\\n\", Pg_inv.value)\n",
    "print(\"lambda_slack_inv:\\n\", lambda_slack_inv.value)\n",
    "print(\"nu_max_inv:\\n\", nu_max_inv.value)\n",
    "print(\"nu_min_inv:\\n\", nu_min_inv.value)\n",
    "print(\"mu_min_inv:\\n\", mu_min_inv.value)\n",
    "print(\"mu_max_inv:\\n\", mu_max_inv.value)\n",
    "# print(\"epsilon_line:\\n\", epsilon_line.value)\n",
    "# print(\"epsilon_gen:\\n\", epsilon_gen.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
